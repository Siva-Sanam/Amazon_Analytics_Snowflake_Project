{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5ad6cc",
   "metadata": {},
   "source": [
    "# Snowflake + Amazon Snowpark ETL Setup\n",
    "This notebook walks through creating a Snowflake virtual warehouse and user, and setting up connectivity via Snowpark for ETL operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89792b5c",
   "metadata": {},
   "source": [
    "## Step 1: Create User & Virtual Warehouse\n",
    "We will create a virtual warehouse and a dedicated user for running Snowpark-based ETL workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step-1 Create User & Virtual Warehouse \n",
    "Lets create a virtual warehouse and user account that will be used to run Snowpark ETL workload. \n",
    "-- create a virtual warehouse \n",
    "use role sysadmin; \n",
    "create warehouse snowpark_etl_wh \n",
    "with \n",
    "warehouse_size = 'medium' \n",
    "warehouse_type = 'standard' \n",
    "auto_suspend = 60 \n",
    "auto_resume = true \n",
    "min_cluster_count = 1 \n",
    "max_cluster_count = 1 \n",
    "scaling_policy = 'standard'; \n",
    "-- create a snowpark user (it can only be created using accountadmin role) \n",
    "user role accountadmin; \n",
    "create user snowpark_user \n",
    "password = 'Test@12$4' \n",
    "comment = 'this is a s snowpark user' \n",
    "default_role = sysadmin \n",
    "default_secondary_roles = ('ALL') \n",
    "must_change_password = false; \n",
    "-- grants \n",
    "grant role sysadmin to user snowpark_user_01; \n",
    "grant USAGE on warehouse snowpark_etl_wh_01 to role sysadmin;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7211",
   "metadata": {},
   "source": [
    "## Step 2: Validate Snowpark Snowflake Connectivity\n",
    "We will now validate the Snowpark session creation and run a sample query to fetch customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snowpark Snowflake Connectivity Validation\n",
    "Validate if we are able to use the user and virtual warehouse created in step-1 \n",
    "from snowflake.snowpark import Session \n",
    "import sys \n",
    "import logging \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"<sf-account>\", \n",
    "\"USER\":\"snowpark_user\", \n",
    "\"PASSWORD\":\"Test@12$4\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"SNOWFLAKE_SAMPLE_DATA\", \n",
    "\"SCHEMA\":\"TPCH_SF1\", \n",
    "\"WAREHOUSE\":\"SNOWPARK_ETL_WH\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def main(): \n",
    "session = get_snowpark_session() \n",
    "context_df = session.sql(\"select current_role(), current_database(), current_schema(), current_warehouse()\") \n",
    "context_df.show(2) \n",
    "customer_df = session.sql(\"select c_custkey,c_name,c_phone,c_mktsegment from snowflake_sample_data.tpch_sf1.customer limit 10\") \n",
    "customer_df.show(5) \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "Step-2 Database & Schema Object \n",
    "Creating sales_dwh and 5 schemas under the sales_dwh. \n",
    "Overall Data Flow Diagram \n",
    "-- create database \n",
    "create database if not exists sales_dwh; \n",
    "use database sales_dwh; \n",
    "create schema if not exists source; -- will have source stage etc \n",
    "create schema if not exists curated; -- data curation and de-duplication \n",
    "create schema if not exists consumption; -- fact & dimension \n",
    "create schema if not exists audit; -- to capture all audit records \n",
    "create schema if not exists common; -- for file formats sequence object etc \n",
    "Step-4.1 Internal Stage In Source Schema \n",
    "Creating internal stage that will host all the data setup available in our local machine. \n",
    "-- creating internal stage within source schema. \n",
    "use schema source; \n",
    "create or replace stage my_internal_stg; \n",
    "-- following put command can be executed \n",
    "/* \n",
    "-- csv example \n",
    "put file:///tmp/sales/source=IN/format=csv/date=2022-02-22/order-20220222.csv @sales_dwh.source.my_internal_stg/sales/source=IN/format=csv/date=2022-02-22 auto_compress=False overwrite=True, parallel=3 ; \n",
    "put file:///tmp/sales/source=IN/format=csv/date=2021-04-26/order-20210426.csv @sales_dwh.source.my_internal_stg/sales/source=IN/format=csv/date=2021-04-26 auto_compress=False overwrite=True, parallel=3 ; \n",
    "-- json example \n",
    "put file:///tmp/sales/source=FR/format=json/date=2022-02-22/order-20220222.json @sales_dwh.source.my_internal_stg/sales/source=FR/format=json/date=2022-02-22 auto_compress=False overwrite=True, parallel=3 ; \n",
    "put file:///tmp/sales/source=FR/format=json/date=2021-04-26/order-20210426.json @sales_dwh.source.my_internal_stg/sales/source=FR/format=json/date=2021-04-26 auto_compress=False overwrite=True, parallel=3 ; \n",
    "-- parquet example \n",
    "put file:///tmp/sales/source=US/format=parquet/date=2022-02-22/order-20220222.snappy.parquet @sales_dwh.source.my_internal_stg/sales/source=US/format=parquet/date=2022-02-22 auto_compress=False overwrite=True, parallel=3 ; \n",
    "put file:///tmp/sales/source=US/format=parquet/date=2021-04-26/order-20210426.snappy.parquet @sales_dwh.source.my_internal_stg/sales/source=US/format=parquet/date=2021-04-26 auto_compress=False overwrite=True, parallel=3 ; \n",
    "*/ \n",
    "Step 4.2 Loading Data To Internal Stage Using Snowpark File API \n",
    "Following Snowpark Program is using File API to read the data from local machine and loading into Snowpark Internal Stage. \n",
    "import os \n",
    "from snowflake.snowpark import Session \n",
    "import sys \n",
    "import logging \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"<your-snowflake-account>\", \n",
    "\"USER\":\"<your-user>\", \n",
    "\"PASSWORD\":\"<your-pwd>\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def traverse_directory(directory,file_extension) -> list: \n",
    "local_file_path = [] \n",
    "file_name = [] # List to store CSV file paths \n",
    "partition_dir = [] \n",
    "print(directory) \n",
    "for root, dirs, files in os.walk(directory): \n",
    "for file in files: \n",
    "if file.endswith(file_extension): \n",
    "file_path = os.path.join(root, file) \n",
    "file_name.append(file) \n",
    "partition_dir.append(root.replace(directory, \"\")) \n",
    "local_file_path.append(file_path) \n",
    "return file_name,partition_dir,local_file_path \n",
    "def main(): \n",
    "# Specify the directory path to traverse \n",
    "directory_path = '/tmp/snowpark-e2e/' \n",
    "csv_file_name, csv_partition_dir , csv_local_file_path= traverse_directory(directory_path,'.csv') \n",
    "parquet_file_name, parquet_partition_dir , parquet_local_file_path= traverse_directory(directory_path,'.parquet') \n",
    "json_file_name, json_partition_dir , json_local_file_path= traverse_directory(directory_path,'.json') \n",
    "stage_location = '@sales_dwh.source.my_internal_stg' \n",
    "csv_index = 0 \n",
    "for file_element in csv_file_name: \n",
    "put_result = ( \n",
    "get_snowpark_session().file.put( \n",
    "csv_local_file_path[csv_index], \n",
    "stage_location+\"/\"+csv_partition_dir[csv_index], \n",
    "auto_compress=False, overwrite=True, parallel=10) \n",
    ") \n",
    "#put_result(file_element,\" => \",put_result[0].status) \n",
    "csv_index+=1 \n",
    "parquet_index = 0 \n",
    "for file_element in parquet_file_name: \n",
    "put_result = ( \n",
    "get_snowpark_session().file.put( \n",
    "parquet_local_file_path[parquet_index], \n",
    "stage_location+\"/\"+parquet_partition_dir[parquet_index], \n",
    "auto_compress=False, overwrite=True, parallel=10) \n",
    ") \n",
    "#put_result(file_element,\" => \",put_result[0].status) \n",
    "parquet_index+=1 \n",
    "json_index = 0 \n",
    "for file_element in parquet_file_name: \n",
    "put_result = ( \n",
    "get_snowpark_session().file.put( \n",
    "json_local_file_path[json_index], \n",
    "stage_location+\"/\"+json_partition_dir[json_index], \n",
    "auto_compress=False, overwrite=True, parallel=10) \n",
    ") \n",
    "#put_result(file_element,\" => \",put_result[0].status) \n",
    "json_index+=1 \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "Step-5 File Format Objects Within Common Schema \n",
    "Following file formate will be created under common schema and will be used to read and process the data from the internal stage location. \n",
    "use schema common; \n",
    "-- create file formats csv (India), json (France), Parquet (USA) \n",
    "create or replace file format my_csv_format \n",
    "type = csv \n",
    "field_delimiter = ',' \n",
    "skip_header = 1 \n",
    "null_if = ('null', 'null') \n",
    "empty_field_as_null = true \n",
    "field_optionally_enclosed_by = '\\042' \n",
    "compression = auto; \n",
    "-- json file format with strip outer array true \n",
    "create or replace file format my_json_format \n",
    "type = json \n",
    "strip_outer_array = true \n",
    "compression = auto; \n",
    "-- parquet file format \n",
    "create or replace file format my_parquet_format \n",
    "type = parquet \n",
    "compression = snappy; \n",
    "Step-5.1 Select Statements On Internal Stage (CSV, Parquet, JSON) \n",
    "Once the 3 file formats data loaded into the snowflake internal stage, following select statement can be executed to see if the data is looking good before we move and insert into source schema. \n",
    "-- Internal Stage - Query The CSV Data File Format \n",
    "select \n",
    "t.$1::text as order_id, \n",
    "t.$2::text as customer_name, \n",
    "t.$3::text as mobile_key, \n",
    "t.$4::number as order_quantity, \n",
    "t.$5::number as unit_price, \n",
    "t.$6::number as order_valaue, \n",
    "t.$7::text as promotion_code , \n",
    "t.$8::number(10,2) as final_order_amount, \n",
    "t.$9::number(10,2) as tax_amount, \n",
    "t.$10::date as order_dt, \n",
    "t.$11::text as payment_status, \n",
    "t.$12::text as shipping_status, \n",
    "t.$13::text as payment_method, \n",
    "t.$14::text as payment_provider, \n",
    "t.$15::text as mobile, \n",
    "t.$16::text as shipping_address \n",
    "from \n",
    "@my_internal_stg/sales/source=IN/format=csv/ \n",
    "(file_format => 'sales_dwh.common.my_csv_format') t; \n",
    "-- Internal Stage - Query The Parquet Data File Format \n",
    "select \n",
    "$1:\"Order ID\"::text as orde_id, \n",
    "$1:\"Customer Name\"::text as customer_name, \n",
    "$1:\"Mobile Model\"::text as mobile_key, \n",
    "to_number($1:\"Quantity\") as quantity, \n",
    "to_number($1:\"Price per Unit\") as unit_price, \n",
    "to_decimal($1:\"Total Price\") as total_price, \n",
    "$1:\"Promotion Code\"::text as promotion_code, \n",
    "$1:\"Order Amount\"::number(10,2) as order_amount, \n",
    "to_decimal($1:\"Tax\") as tax, \n",
    "$1:\"Order Date\"::date as order_dt, \n",
    "$1:\"Payment Status\"::text as payment_status, \n",
    "$1:\"Shipping Status\"::text as shipping_status, \n",
    "$1:\"Payment Method\"::text as payment_method, \n",
    "$1:\"Payment Provider\"::text as payment_provider, \n",
    "$1:\"Phone\"::text as phone, \n",
    "$1:\"Delivery Address\"::text as shipping_address \n",
    "from \n",
    "@sales_dwh.source.my_internal_stg/sales/source=US/format=parquet/ \n",
    "(file_format => 'sales_dwh.common.my_parquet_format'); \n",
    "-- Internal Stage - Query The JSON Data File Format \n",
    "select \n",
    "$1:\"Order ID\"::text as orde_id, \n",
    "$1:\"Customer Name\"::text as customer_name, \n",
    "$1:\"Mobile Model\"::text as mobile_key, \n",
    "to_number($1:\"Quantity\") as quantity, \n",
    "to_number($1:\"Price per Unit\") as unit_price, \n",
    "to_decimal($1:\"Total Price\") as total_price, \n",
    "$1:\"Promotion Code\"::text as promotion_code, \n",
    "$1:\"Order Amount\"::number(10,2) as order_amount, \n",
    "to_decimal($1:\"Tax\") as tax, \n",
    "$1:\"Order Date\"::date as order_dt, \n",
    "$1:\"Payment Status\"::text as payment_status, \n",
    "$1:\"Shipping Status\"::text as shipping_status, \n",
    "$1:\"Payment Method\"::text as payment_method, \n",
    "$1:\"Payment Provider\"::text as payment_provider, \n",
    "$1:\"Phone\"::text as phone, \n",
    "$1:\"Delivery Address\"::text as shipping_address \n",
    "from \n",
    "@sales_dwh.source.my_internal_stg/sales/source=FR/format=json/ \n",
    "(file_format => sales_dwh.common.my_json_format); \n",
    "Step-6 Foreign Exchange Rate Data \n",
    "Create Foreign exchange rate data to convert the local currency data (like INR or Euro) to US Dollar so when we create total sales, at global level, so we can build PKI in a single currency and compare the performance. \n",
    "-- put file://my-location/forex/exchange-rate.csv @my_internal_stg/exchange/ parallel=10 auto_compress=false;; \n",
    "list @my_internal_stg/exchange/; \n",
    "use schema common; \n",
    "create or replace transient table exchange_rate( \n",
    "date date, \n",
    "usd2usd decimal(10,7), \n",
    "usd2eu decimal(10,7), \n",
    "usd2can decimal(10,7), \n",
    "usd2uk decimal(10,7), \n",
    "usd2inr decimal(10,7), \n",
    "usd2jp decimal(10,7) \n",
    "); \n",
    "copy into sales_dwh.common.exchange_rate \n",
    "from \n",
    "( \n",
    "select \n",
    "t.$1::date as exchange_dt, \n",
    "to_decimal(t.$2) as usd2usd, \n",
    "to_decimal(t.$3,12,10) as usd2eu, \n",
    "to_decimal(t.$4,12,10) as usd2can, \n",
    "to_decimal(t.$4,12,10) as usd2uk, \n",
    "to_decimal(t.$4,12,10) as usd2inr, \n",
    "to_decimal(t.$4,12,10) as usd2jp \n",
    "from \n",
    "@sales_dwh.source.my_internal_stg/exchange/exchange-rate.csv \n",
    "(file_format => 'sales_dwh.common.my_csv_format') t \n",
    "); \n",
    "Step-7.1 Loading Data From Internal Stage to Source Tables \n",
    "Every time the data moves from internal stage location to source layer within permanent tables, it will add a sequence number that will help to de-duplicate the data set. \n",
    "-- order table \n",
    "use schema source; \n",
    "create or replace sequence in_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for India sales order table'; \n",
    "create or replace sequence us_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for USA sales order table'; \n",
    "create or replace sequence fr_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for France sales order table'; \n",
    "7.2 Source Table DDL Script \n",
    "show sequences; \n",
    "-- India Sales Table in Source Schema (CSV File) \n",
    "create or replace transient table in_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "order_quantity number(38,0), \n",
    "unit_price number(38,0), \n",
    "order_valaue number(38,0), \n",
    "promotion_code varchar(), \n",
    "final_order_amount number(10,2), \n",
    "tax_amount number(10,2), \n",
    "order_dt date, \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "mobile varchar(), \n",
    "shipping_address varchar(), \n",
    "_metadata_file_name varchar(), \n",
    "_metadata_row_numer number(38,0), \n",
    "_metadata_last_modified timestamp_ntz(9) \n",
    "); \n",
    "-- US Sales Table in Source Schema (Parquet File) \n",
    "create or replace transient table us_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "order_quantity number(38,0), \n",
    "unit_price number(38,0), \n",
    "order_valaue number(38,0), \n",
    "promotion_code varchar(), \n",
    "final_order_amount number(10,2), \n",
    "tax_amount number(10,2), \n",
    "order_dt date, \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "phone varchar(), \n",
    "shipping_address varchar(), \n",
    "_metadata_file_name varchar(), \n",
    "_metadata_row_numer number(38,0), \n",
    "_metadata_last_modified timestamp_ntz(9) \n",
    "); \n",
    "-- France Sales Table in Source Schema (JSON File) \n",
    "create or replace transient table fr_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "order_quantity number(38,0), \n",
    "unit_price number(38,0), \n",
    "order_valaue number(38,0), \n",
    "promotion_code varchar(), \n",
    "final_order_amount number(10,2), \n",
    "tax_amount number(10,2), \n",
    "order_dt date, \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "phone varchar(), \n",
    "shipping_address varchar(), \n",
    "_metadata_file_name varchar(), \n",
    "_metadata_row_numer number(38,0), \n",
    "_metadata_last_modified timestamp_ntz(9) \n",
    "); \n",
    "7.3 Snowpark Python Example To Load To Stage \n",
    "Here is the example of snowpark python example to load the data from local machine, where all amazon mobile order data in 3 different formats, CSV, Parquet & JSON can be moved to snowflake internal stage. \n",
    "import sys \n",
    "import logging \n",
    "from snowflake.snowpark import Session, DataFrame \n",
    "from snowflake.snowpark.types import StructType, StringType, StructField, StringType,LongType,DecimalType,DateType,TimestampType \n",
    "from snowflake.snowpark.functions import col,lit,row_number, rank \n",
    "from snowflake.snowpark import Window \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"abc1234\", \n",
    "\"USER\":\"test\", \n",
    "\"PASSWORD\":\"mypassowrd\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def ingest_in_sales(session)-> None: \n",
    "session.sql(\" \\ \n",
    "copy into sales_dwh.source.in_sales_order from ( \\ \n",
    "select \\ \n",
    "in_sales_order_seq.nextval, \\ \n",
    "t.$1::text as order_id, \\ \n",
    "t.$2::text as customer_name, \\ \n",
    "t.$3::text as mobile_key,\\ \n",
    "t.$4::number as order_quantity, \\ \n",
    "t.$5::number as unit_price, \\ \n",
    "t.$6::number as order_valaue, \\ \n",
    "t.$7::text as promotion_code , \\ \n",
    "t.$8::number(10,2) as final_order_amount,\\ \n",
    "t.$9::number(10,2) as tax_amount,\\ \n",
    "t.$10::date as order_dt,\\ \n",
    "t.$11::text as payment_status,\\ \n",
    "t.$12::text as shipping_status,\\ \n",
    "t.$13::text as payment_method,\\ \n",
    "t.$14::text as payment_provider,\\ \n",
    "t.$15::text as mobile,\\ \n",
    "t.$16::text as shipping_address,\\ \n",
    "metadata$filename as stg_file_name,\\ \n",
    "metadata$file_row_number as stg_row_numer,\\ \n",
    "metadata$file_last_modified as stg_last_modified\\ \n",
    "from \\ \n",
    "@sales_dwh.source.my_internal_stg/sales/source=IN/format=csv/ \\ \n",
    "( \\ \n",
    "file_format => 'sales_dwh.common.my_csv_format' \\ \n",
    ") t ) on_error = 'Continue' \\ \n",
    "\" \n",
    ").collect() \n",
    "def ingest_us_sales(session)-> None: \n",
    "session.sql(' \\ \n",
    "copy into sales_dwh.source.us_sales_order \\ \n",
    "from \\ \n",
    "( \\ \n",
    "select \\ \n",
    "us_sales_order_seq.nextval, \\ \n",
    "$1:\"Order ID\"::text as orde_id, \\ \n",
    "$1:\"Customer Name\"::text as customer_name,\\ \n",
    "$1:\"Mobile Model\"::text as mobile_key,\\ \n",
    "to_number($1:\"Quantity\") as quantity,\\ \n",
    "to_number($1:\"Price per Unit\") as unit_price,\\ \n",
    "to_decimal($1:\"Total Price\") as total_price,\\ \n",
    "$1:\"Promotion Code\"::text as promotion_code,\\ \n",
    "$1:\"Order Amount\"::number(10,2) as order_amount,\\ \n",
    "to_decimal($1:\"Tax\") as tax,\\ \n",
    "$1:\"Order Date\"::date as order_dt,\\ \n",
    "$1:\"Payment Status\"::text as payment_status,\\ \n",
    "$1:\"Shipping Status\"::text as shipping_status,\\ \n",
    "$1:\"Payment Method\"::text as payment_method,\\ \n",
    "$1:\"Payment Provider\"::text as payment_provider,\\ \n",
    "$1:\"Phone\"::text as phone,\\ \n",
    "$1:\"Delivery Address\"::text as shipping_address,\\ \n",
    "metadata$filename as stg_file_name,\\ \n",
    "metadata$file_row_number as stg_row_numer,\\ \n",
    "metadata$file_last_modified as stg_last_modified\\ \n",
    "from \\ \n",
    "@sales_dwh.source.my_internal_stg/sales/source=US/format=parquet/\\ \n",
    "(file_format => sales_dwh.common.my_parquet_format)\\ \n",
    ") on_error = continue \\ \n",
    "' \n",
    ").collect() \n",
    "def ingest_fr_sales(session)-> None: \n",
    "session.sql(' \\ \n",
    "copy into sales_dwh.source.fr_sales_order \\ \n",
    "from \\ \n",
    "( \\ \n",
    "select \\ \n",
    "sales_dwh.source.fr_sales_order_seq.nextval, \\ \n",
    "$1:\"Order ID\"::text as orde_id, \\ \n",
    "$1:\"Customer Name\"::text as customer_name, \\ \n",
    "$1:\"Mobile Model\"::text as mobile_key, \\ \n",
    "to_number($1:\"Quantity\") as quantity, \\ \n",
    "to_number($1:\"Price per Unit\") as unit_price, \\ \n",
    "to_decimal($1:\"Total Price\") as total_price, \\ \n",
    "$1:\"Promotion Code\"::text as promotion_code, \\ \n",
    "$1:\"Order Amount\"::number(10,2) as order_amount, \\ \n",
    "to_decimal($1:\"Tax\") as tax, \\ \n",
    "$1:\"Order Date\"::date as order_dt, \\ \n",
    "$1:\"Payment Status\"::text as payment_status, \\ \n",
    "$1:\"Shipping Status\"::text as shipping_status, \\ \n",
    "$1:\"Payment Method\"::text as payment_method, \\ \n",
    "$1:\"Payment Provider\"::text as payment_provider, \\ \n",
    "$1:\"Phone\"::text as phone, \\ \n",
    "$1:\"Delivery Address\"::text as shipping_address , \\ \n",
    "metadata$filename as stg_file_name,\\ \n",
    "metadata$file_row_number as stg_row_numer,\\ \n",
    "metadata$file_last_modified as stg_last_modified\\ \n",
    "from \\ \n",
    "@sales_dwh.source.my_internal_stg/sales/source=FR/format=json/\\ \n",
    "(file_format => sales_dwh.common.my_json_format)\\ \n",
    ") on_error=continue\\ \n",
    "' \n",
    ").collect() \n",
    "def main(): \n",
    "#get the session object and get dataframe \n",
    "session = get_snowpark_session() \n",
    "#ingest in sales data \n",
    "ingest_in_sales(session) \n",
    "#ingest in sales data \n",
    "ingest_us_sales(session) \n",
    "#ingest in sales data \n",
    "ingest_fr_sales(session) \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "Step-8 Loading Data From Source To Curated Layer \n",
    "8.1 Sequence Object Under Curated Schema Layer \n",
    "-- Following are for curated schema \n",
    "-- ----------------------------------- \n",
    "use schema curated; \n",
    "create or replace sequence in_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for India sales order table'; \n",
    "create or replace sequence us_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for USA sales order table'; \n",
    "create or replace sequence fr_sales_order_seq \n",
    "start = 1 \n",
    "increment = 1 \n",
    "comment='This is sequence for France sales order table'; \n",
    "8.2 Curated Layer DDL \n",
    "use schema curated; \n",
    "-- curated India sales order table \n",
    "create or replace table in_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "order_dt date, \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "country varchar(), \n",
    "region varchar(), \n",
    "order_quantity number(38,0), \n",
    "local_currency varchar(), \n",
    "local_unit_price number(38,0), \n",
    "promotion_code varchar(), \n",
    "local_total_order_amt number(10,2), \n",
    "local_tax_amt number(10,2), \n",
    "exhchange_rate number(15,7), \n",
    "us_total_order_amt number(23,8), \n",
    "usd_tax_amt number(23,8), \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "conctact_no varchar(), \n",
    "shipping_address varchar() \n",
    "); \n",
    "-- curated US sales order table \n",
    "create or replace table us_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "order_dt date, \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "country varchar(), \n",
    "region varchar(), \n",
    "order_quantity number(38,0), \n",
    "local_currency varchar(), \n",
    "local_unit_price number(38,0), \n",
    "promotion_code varchar(), \n",
    "local_total_order_amt number(10,2), \n",
    "local_tax_amt number(10,2), \n",
    "exhchange_rate number(15,7), \n",
    "us_total_order_amt number(23,8), \n",
    "usd_tax_amt number(23,8), \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "conctact_no varchar(), \n",
    "shipping_address varchar() \n",
    "); \n",
    "-- -- curated FR sales order table \n",
    "create or replace table fr_sales_order ( \n",
    "sales_order_key number(38,0), \n",
    "order_id varchar(), \n",
    "order_dt date, \n",
    "customer_name varchar(), \n",
    "mobile_key varchar(), \n",
    "country varchar(), \n",
    "region varchar(), \n",
    "order_quantity number(38,0), \n",
    "local_currency varchar(), \n",
    "local_unit_price number(38,0), \n",
    "promotion_code varchar(), \n",
    "local_total_order_amt number(10,2), \n",
    "local_tax_amt number(10,2), \n",
    "exhchange_rate number(15,7), \n",
    "us_total_order_amt number(23,8), \n",
    "usd_tax_amt number(23,8), \n",
    "payment_status varchar(), \n",
    "shipping_status varchar(), \n",
    "payment_method varchar(), \n",
    "payment_provider varchar(), \n",
    "conctact_no varchar(), \n",
    "shipping_address varchar() \n",
    "); \n",
    "8.3 Snowpark Python — Source To Curated (IN) \n",
    "import sys \n",
    "import logging \n",
    "from snowflake.snowpark import Session, DataFrame \n",
    "from snowflake.snowpark.functions import col,lit,row_number, rank \n",
    "from snowflake.snowpark import Window \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"abc1234\", \n",
    "\"USER\":\"demo\", \n",
    "\"PASSWORD\":\"simplepwd\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def filter_dataset(df, column_name, filter_criterian) -> DataFrame: \n",
    "# Payment Status = Paid \n",
    "# Shipping = Delivered \n",
    "return_df = df.filter(col(column_name) == filter_criterian) \n",
    "return return_df \n",
    "def main(): \n",
    "#get the session object and get dataframe \n",
    "session = get_snowpark_session() \n",
    "sales_df = session.sql(\"select * from in_sales_order\") \n",
    "# apply filter to select only paid and delivered sale orders \n",
    "# select * from in_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "paid_sales_df = filter_dataset(sales_df,'PAYMENT_STATUS','Paid') \n",
    "shipped_sales_df = filter_dataset(paid_sales_df,'SHIPPING_STATUS','Delivered') \n",
    "# adding country and region to the data frame \n",
    "# select *, 'IN' as Country, 'APAC' as Region from in_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "country_sales_df = shipped_sales_df.with_column('Country',lit('IN')).with_column('Region',lit('APAC')) \n",
    "# join to add forex calculation \n",
    "forex_df = session.sql(\"select * from sales_dwh.common.exchange_rate\") \n",
    "sales_with_forext_df = country_sales_df.join(forex_df,country_sales_df['order_dt']==forex_df['echange_rate_dt'],join_type='outer') \n",
    "#sales_with_forext_df.show(2) \n",
    "#de-duplication \n",
    "#print(sales_with_forext_df.count()) \n",
    "unique_orders = sales_with_forext_df.with_column('order_rank',rank().over(Window.partitionBy(col(\"order_dt\")).order_by(col('_metadata_last_modified').desc()))).filter(col(\"order_rank\")==1).select(col('SALES_ORDER_KEY').alias('unique_sales_order_key')) \n",
    "final_sales_df = unique_orders.join(sales_with_forext_df,unique_orders['unique_sales_order_key']==sales_with_forext_df['SALES_ORDER_KEY'],join_type='inner') \n",
    "final_sales_df = final_sales_df.select( \n",
    "col('SALES_ORDER_KEY'), \n",
    "col('ORDER_ID'), \n",
    "col('ORDER_DT'), \n",
    "col('CUSTOMER_NAME'), \n",
    "col('MOBILE_KEY'), \n",
    "col('Country'), \n",
    "col('Region'), \n",
    "col('ORDER_QUANTITY'), \n",
    "lit('INR').alias('LOCAL_CURRENCY'), \n",
    "col('UNIT_PRICE').alias('LOCAL_UNIT_PRICE'), \n",
    "col('PROMOTION_CODE').alias('PROMOTION_CODE'), \n",
    "col('FINAL_ORDER_AMOUNT').alias('LOCAL_TOTAL_ORDER_AMT'), \n",
    "col('TAX_AMOUNT').alias('local_tax_amt'), \n",
    "col('USD2INR').alias(\"Exhchange_Rate\"), \n",
    "(col('FINAL_ORDER_AMOUNT')/col('USD2INR')).alias('US_TOTAL_ORDER_AMT'), \n",
    "(col('TAX_AMOUNT')/col('USD2INR')).alias('USD_TAX_AMT'), \n",
    "col('payment_status'), \n",
    "col('shipping_status'), \n",
    "col('payment_method'), \n",
    "col('payment_provider'), \n",
    "col('mobile').alias('conctact_no'), \n",
    "col('shipping_address') \n",
    ") \n",
    "#final_sales_df.show(5) \n",
    "final_sales_df.write.save_as_table(\"sales_dwh.curated.in_sales_order\",mode=\"append\") \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "8.4 Snowpark Python — Source To Curated (US) \n",
    "import sys \n",
    "import logging \n",
    "from snowflake.snowpark import Session, DataFrame \n",
    "from snowflake.snowpark.functions import col,lit,row_number, rank \n",
    "from snowflake.snowpark import Window \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"abc1234\", \n",
    "\"USER\":\"demo\", \n",
    "\"PASSWORD\":\"simplepwd\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def filter_dataset(df, column_name, filter_criterian) -> DataFrame: \n",
    "# Payment Status = Paid \n",
    "# Shipping = Delivered \n",
    "return_df = df.filter(col(column_name) == filter_criterian) \n",
    "return return_df \n",
    "def main(): \n",
    "#get the session object and get dataframe \n",
    "session = get_snowpark_session() \n",
    "sales_df = session.sql(\"select * from us_sales_order\") \n",
    "# apply filter to select only paid and delivered sale orders \n",
    "# select * from us_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "paid_sales_df = filter_dataset(sales_df,'PAYMENT_STATUS','Paid') \n",
    "shipped_sales_df = filter_dataset(paid_sales_df,'SHIPPING_STATUS','Delivered') \n",
    "# adding country and region to the data frame \n",
    "# select *, 'IN' as Country, 'APAC' as Region from us_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "country_sales_df = shipped_sales_df.with_column('Country',lit('US')).with_column('Region',lit('NA')) \n",
    "# join to add forex calculation \n",
    "forex_df = session.sql(\"select * from sales_dwh.common.exchange_rate\") \n",
    "sales_with_forext_df = country_sales_df.join(forex_df,country_sales_df['order_dt']==forex_df['echange_rate_dt'],join_type='outer') \n",
    "#sales_with_forext_df.show(2) \n",
    "#de-duplication \n",
    "print(sales_with_forext_df.count()) \n",
    "unique_orders = sales_with_forext_df.with_column('order_rank',rank().over(Window.partitionBy(col(\"order_dt\")).order_by(col('_metadata_last_modified').desc()))).filter(col(\"order_rank\")==1).select(col('SALES_ORDER_KEY').alias('unique_sales_order_key')) \n",
    "final_sales_df = unique_orders.join(sales_with_forext_df,unique_orders['unique_sales_order_key']==sales_with_forext_df['SALES_ORDER_KEY'],join_type='inner') \n",
    "final_sales_df = final_sales_df.select( \n",
    "col('SALES_ORDER_KEY'), \n",
    "col('ORDER_ID'), \n",
    "col('ORDER_DT'), \n",
    "col('CUSTOMER_NAME'), \n",
    "col('MOBILE_KEY'), \n",
    "col('Country'), \n",
    "col('Region'), \n",
    "col('ORDER_QUANTITY'), \n",
    "lit('USD').alias('LOCAL_CURRENCY'), \n",
    "col('UNIT_PRICE').alias('LOCAL_UNIT_PRICE'), \n",
    "col('PROMOTION_CODE').alias('PROMOTION_CODE'), \n",
    "col('FINAL_ORDER_AMOUNT').alias('LOCAL_TOTAL_ORDER_AMT'), \n",
    "col('TAX_AMOUNT').alias('local_tax_amt'), \n",
    "col('USD2INR').alias(\"Exhchange_Rate\"), \n",
    "(col('FINAL_ORDER_AMOUNT')/col('USD2USD')).alias('US_TOTAL_ORDER_AMT'), \n",
    "(col('TAX_AMOUNT')/col('USD2USD')).alias('USD_TAX_AMT'), \n",
    "col('payment_status'), \n",
    "col('shipping_status'), \n",
    "col('payment_method'), \n",
    "col('payment_provider'), \n",
    "col('phone').alias('conctact_no'), \n",
    "col('shipping_address') \n",
    ") \n",
    "#final_sales_df.show(5) \n",
    "final_sales_df.write.save_as_table(\"sales_dwh.curated.us_sales_order\",mode=\"append\") \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "8.5 Snowpark Python — Source To Curated (FR) \n",
    "import sys \n",
    "import logging \n",
    "from snowflake.snowpark import Session, DataFrame \n",
    "from snowflake.snowpark.functions import col,lit,row_number, rank \n",
    "from snowflake.snowpark import Window \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"abc1234\", \n",
    "\"USER\":\"demo\", \n",
    "\"PASSWORD\":\"simplepwd\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "def filter_dataset(df, column_name, filter_criterian) -> DataFrame: \n",
    "# Payment Status = Paid \n",
    "# Shipping = Delivered \n",
    "return_df = df.filter(col(column_name) == filter_criterian) \n",
    "return return_df \n",
    "def main(): \n",
    "#get the session object and get dataframe \n",
    "session = get_snowpark_session() \n",
    "sales_df = session.sql(\"select * from us_sales_order\") \n",
    "# apply filter to select only paid and delivered sale orders \n",
    "# select * from us_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "paid_sales_df = filter_dataset(sales_df,'PAYMENT_STATUS','Paid') \n",
    "shipped_sales_df = filter_dataset(paid_sales_df,'SHIPPING_STATUS','Delivered') \n",
    "# adding country and region to the data frame \n",
    "# select *, 'IN' as Country, 'APAC' as Region from us_sales_order where PAYMENT_STATUS = 'Paid' and SHIPPING_STATUS = 'Delivered' \n",
    "country_sales_df = shipped_sales_df.with_column('Country',lit('FR')).with_column('Region',lit('EU')) \n",
    "# join to add forex calculation \n",
    "forex_df = session.sql(\"select * from sales_dwh.common.exchange_rate\") \n",
    "sales_with_forext_df = country_sales_df.join(forex_df,country_sales_df['order_dt']==forex_df['echange_rate_dt'],join_type='outer') \n",
    "#sales_with_forext_df.show(2) \n",
    "#de-duplication \n",
    "print(sales_with_forext_df.count()) \n",
    "unique_orders = sales_with_forext_df.with_column('order_rank',rank().over(Window.partitionBy(col(\"order_dt\")).order_by(col('_metadata_last_modified').desc()))).filter(col(\"order_rank\")==1).select(col('SALES_ORDER_KEY').alias('unique_sales_order_key')) \n",
    "final_sales_df = unique_orders.join(sales_with_forext_df,unique_orders['unique_sales_order_key']==sales_with_forext_df['SALES_ORDER_KEY'],join_type='inner') \n",
    "final_sales_df = final_sales_df.select( \n",
    "col('SALES_ORDER_KEY'), \n",
    "col('ORDER_ID'), \n",
    "col('ORDER_DT'), \n",
    "col('CUSTOMER_NAME'), \n",
    "col('MOBILE_KEY'), \n",
    "col('Country'), \n",
    "col('Region'), \n",
    "col('ORDER_QUANTITY'), \n",
    "lit('EUR').alias('LOCAL_CURRENCY'), \n",
    "col('UNIT_PRICE').alias('LOCAL_UNIT_PRICE'), \n",
    "col('PROMOTION_CODE').alias('PROMOTION_CODE'), \n",
    "col('FINAL_ORDER_AMOUNT').alias('LOCAL_TOTAL_ORDER_AMT'), \n",
    "col('TAX_AMOUNT').alias('local_tax_amt'), \n",
    "col('USD2FR').alias(\"Exhchange_Rate\"), \n",
    "(col('FINAL_ORDER_AMOUNT')/col('USD2FR')).alias('US_TOTAL_ORDER_AMT'), \n",
    "(col('TAX_AMOUNT')/col('USD2FR')).alias('USD_TAX_AMT'), \n",
    "col('payment_status'), \n",
    "col('shipping_status'), \n",
    "col('payment_method'), \n",
    "col('payment_provider'), \n",
    "col('phone').alias('conctact_no'), \n",
    "col('shipping_address') \n",
    ") \n",
    "#final_sales_df.show(5) \n",
    "final_sales_df.write.save_as_table(\"sales_dwh.curated.fr_sales_order\",mode=\"append\") \n",
    "if __name__ == '__main__': \n",
    "main() \n",
    "Step-9 Working on Consumption Layer \n",
    "Step-9.1 Dimension Tables & Sequence Object \n",
    "-- region dimension \n",
    "use schema consumption; \n",
    "create or replace sequence region_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table region_dim( \n",
    "region_id_pk number primary key, \n",
    "Country text, \n",
    "Region text, \n",
    "isActive text(1) \n",
    "); \n",
    "-- product dimension \n",
    "use schema consumption; \n",
    "create or replace sequence product_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table product_dim( \n",
    "product_id_pk number primary key, \n",
    "Mobile_key text, \n",
    "Brand text, \n",
    "Model text, \n",
    "Color text, \n",
    "Memory text, \n",
    "isActive text(1) \n",
    "); \n",
    "-- promo_code dimension \n",
    "use schema consumption; \n",
    "create or replace sequence promo_code_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table promo_code_dim( \n",
    "promo_code_id_pk number primary key, \n",
    "promo_code text, \n",
    "isActive text(1) \n",
    "); \n",
    "-- customer dimension \n",
    "use schema consumption; \n",
    "create or replace sequence customer_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table customer_dim( \n",
    "customer_id_pk number primary key, \n",
    "customer_name text, \n",
    "CONCTACT_NO text, \n",
    "SHIPPING_ADDRESS text, \n",
    "country text, \n",
    "region text, \n",
    "isActive text(1) \n",
    "); \n",
    "-- payment dimension \n",
    "use schema consumption; \n",
    "create or replace sequence payment_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table payment_dim( \n",
    "payment_id_pk number primary key, \n",
    "PAYMENT_METHOD text, \n",
    "PAYMENT_PROVIDER text, \n",
    "country text, \n",
    "region text, \n",
    "isActive text(1) \n",
    "); \n",
    "-- date dimension \n",
    "use schema consumption; \n",
    "create or replace sequence date_dim_seq start = 1 increment = 1; \n",
    "create or replace transient table date_dim( \n",
    "date_id_pk int primary key, \n",
    "order_dt date, \n",
    "order_year int, \n",
    "oder_month int, \n",
    "order_quater int, \n",
    "order_day int, \n",
    "order_dayofweek int, \n",
    "order_dayname text, \n",
    "order_dayofmonth int, \n",
    "order_weekday text \n",
    "); \n",
    "-- fact tables \n",
    "create or replace table sales_fact ( \n",
    "order_id_pk number(38,0), \n",
    "order_code varchar(), \n",
    "date_id_fk number(38,0), \n",
    "region_id_fk number(38,0), \n",
    "customer_id_fk number(38,0), \n",
    "payment_id_fk number(38,0), \n",
    "product_id_fk number(38,0), \n",
    "promo_code_id_fk number(38,0), \n",
    "order_quantity number(38,0), \n",
    "local_total_order_amt number(10,2), \n",
    "local_tax_amt number(10,2), \n",
    "exhchange_rate number(15,7), \n",
    "us_total_order_amt number(23,8), \n",
    "usd_tax_amt number(23,8) \n",
    "); \n",
    "-- Table Containts \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_region FOREIGN KEY (REGION_ID_FK) REFERENCES region_dim (REGION_ID_PK) NOT ENFORCED; \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_date FOREIGN KEY (DATE_ID_FK) REFERENCES date_dim (DATE_ID_PK) NOT ENFORCED; \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_customer FOREIGN KEY (CUSTOMER_ID_FK) REFERENCES customer_dim (CUSTOMER_ID_PK) NOT ENFORCED; \n",
    "-- \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_payment FOREIGN KEY (PAYMENT_ID_FK) REFERENCES payment_dim (PAYMENT_ID_PK) NOT ENFORCED; \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_product FOREIGN KEY (PRODUCT_ID_FK) REFERENCES product_dim (PRODUCT_ID_PK) NOT ENFORCED; \n",
    "alter table sales_fact add \n",
    "constraint fk_sales_promot FOREIGN KEY (PROMO_CODE_ID_FK) REFERENCES promo_code_dim (PROMO_CODE_ID_PK) NOT ENFORCED; \n",
    "9.2 Curated To Model Snowpark Python Example \n",
    "import sys \n",
    "import logging \n",
    "import pandas as pd \n",
    "from snowflake.snowpark import Session, DataFrame, CaseExpr \n",
    "from snowflake.snowpark.functions import col,lit,row_number, rank, split,cast, when, expr,min, max \n",
    "from snowflake.snowpark.types import StructType, StringType, StructField, StringType,LongType,DecimalType,DateType,TimestampType \n",
    "from snowflake.snowpark import Window \n",
    "# initiate logging at info level \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%I:%M:%S') \n",
    "# snowpark session \n",
    "def get_snowpark_session() -> Session: \n",
    "connection_parameters = { \n",
    "\"ACCOUNT\":\"abc1234\", \n",
    "\"USER\":\"demo\", \n",
    "\"PASSWORD\":\"simplepwd\", \n",
    "\"ROLE\":\"SYSADMIN\", \n",
    "\"DATABASE\":\"sales_dwh\", \n",
    "\"SCHEMA\":\"source\" \n",
    "} \n",
    "# creating snowflake session object \n",
    "return Session.builder.configs(connection_parameters).create() \n",
    "# This is a simple dim table having nation and region. \n",
    "# fields are 'Country','Region' \n",
    "def create_region_dim(all_sales_df,session)-> None: \n",
    "region_dim_df = all_sales_df.groupBy(col(\"Country\"),col(\"Region\")).count() \n",
    "region_dim_df.show(2) \n",
    "region_dim_df = region_dim_df.with_column(\"isActive\",lit('Y')) \n",
    "region_dim_df = region_dim_df.selectExpr(\"sales_dwh.source.region_dim_seq.nextval as region_id_pk\",\"Country\", \"Region\", \"isActive\") \n",
    "#region_dim_df.write.save_as_table('sales_dwh.consumption.region_dim',mode=\"append\") \n",
    "region_dim_df.show(5) \n",
    "# part 2 where delta data will be processed \n",
    "existing_region_dim_df = session.sql(\"select Country, Region from sales_dwh.consumption.region_dim\") \n",
    "region_dim_df = region_dim_df.join(existing_region_dim_df,region_dim_df['Country']==existing_region_dim_df['Country'],join_type='leftanti') \n",
    "region_dim_df.show(5) \n",
    "intsert_cnt = int(region_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "region_dim_df.write.save_as_table(\"sales_dwh.consumption.region_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "# have exclude key \n",
    "def create_product_dim(all_sales_df,session)-> None: \n",
    "product_dim_df = all_sales_df.with_column(\"Brand\",split(col('MOBILE_KEY'),lit('/'))[0]) \\ \n",
    ".with_column(\"Model\",split(col('MOBILE_KEY'),lit('/'))[1]) \\ \n",
    ".with_column(\"Color\",split(col('MOBILE_KEY'),lit('/'))[2]) \\ \n",
    ".with_column(\"Memory\",split(col('MOBILE_KEY'),lit('/'))[3]) \\ \n",
    ".select(col('mobile_key'),col('Brand'),col('Model'),col('Color'),col('Memory')) \n",
    "product_dim_df = product_dim_df.select(col('mobile_key'), \\ \n",
    "cast(col('Brand'), StringType()).as_(\"Brand\"),\\ \n",
    "cast(col('Model'), StringType()).as_(\"Model\"),\\ \n",
    "cast(col('Color'), StringType()).as_(\"Color\"),\\ \n",
    "cast(col('Memory'), StringType()).as_(\"Memory\")\\ \n",
    ") \n",
    "product_dim_df = product_dim_df.groupBy(col('mobile_key'),col(\"Brand\"),col(\"Model\"),col(\"Color\"),col(\"Memory\")).count() \n",
    "product_dim_df = product_dim_df.with_column(\"isActive\",lit('Y')) \n",
    "#fetch existing product dim records. \n",
    "existing_product_dim_df = session.sql(\"select mobile_key, Brand, Model, Color, Memory from sales_dwh.consumption.product_dim\") \n",
    "existing_product_dim_df.count() \n",
    "product_dim_df = product_dim_df.join(existing_product_dim_df,[\"mobile_key\", \"Brand\", \"Model\", \"Color\", \"Memory\"],join_type='leftanti') \n",
    "product_dim_df.show(5) \n",
    "product_dim_df = product_dim_df.selectExpr(\"sales_dwh.consumption.product_dim_seq.nextval as product_id_pk\",\"mobile_key\",\"Brand\", \"Model\",\"Color\",\"Memory\", \"isActive\") \n",
    "product_dim_df.show(5) \n",
    "intsert_cnt = int(product_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "product_dim_df.write.save_as_table(\"sales_dwh.consumption.product_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "def create_promocode_dim(all_sales_df,session)-> None: \n",
    "promo_code_dim_df = all_sales_df.with_column( \"promotion_code\", expr(\"case when promotion_code is null then 'NA' else promotion_code end\")) \n",
    "promo_code_dim_df = promo_code_dim_df.groupBy(col(\"promotion_code\"),col(\"country\"),col(\"region\")).count() \n",
    "promo_code_dim_df = promo_code_dim_df.with_column(\"isActive\",lit('Y')) \n",
    "#promo_code_dim_df.show(10) \n",
    "#fetch existing product dim records. \n",
    "existing_promo_code_dim_df = session.sql(\"select promotion_code, country, region from sales_dwh.consumption.promo_code_dim\") \n",
    "promo_code_dim_df = promo_code_dim_df.join(existing_promo_code_dim_df,[\"promotion_code\", \"country\", \"region\"],join_type='leftanti') \n",
    "promo_code_dim_df = promo_code_dim_df.selectExpr(\"sales_dwh.consumption.promo_code_dim_seq.nextval as promo_code_id_pk\",\"promotion_code\", \"country\",\"region\",\"isActive\") \n",
    "intsert_cnt = int(promo_code_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "promo_code_dim_df.write.save_as_table(\"sales_dwh.consumption.promo_code_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "def create_customer_dim(all_sales_df, session) -> None: \n",
    "customer_dim_df = all_sales_df.groupBy(col(\"COUNTRY\"),col(\"REGION\"),col(\"CUSTOMER_NAME\"),col(\"CONCTACT_NO\"),col(\"SHIPPING_ADDRESS\")).count() \n",
    "customer_dim_df = customer_dim_df.with_column(\"isActive\",lit('Y')) \n",
    "customer_dim_df = customer_dim_df.selectExpr(\"customer_name\", \"conctact_no\",\"shipping_address\",\"country\",\"region\" ,\"isactive\") \n",
    "#region_dim_df.write.save_as_table('sales_dwh.consumption.region_dim',mode=\"append\") \n",
    "customer_dim_df.show(5) \n",
    "# part 2 where delta data will be processed \n",
    "existing_customer_dim_df = session.sql(\"select customer_name,conctact_no,shipping_address,country, region from sales_dwh.consumption.customer_dim\") \n",
    "customer_dim_df = customer_dim_df.join(existing_customer_dim_df,[\"customer_name\",\"conctact_no\",\"shipping_address\",\"country\", \"region\"],join_type='leftanti') \n",
    "customer_dim_df = customer_dim_df.selectExpr(\"sales_dwh.consumption.customer_dim_seq.nextval as customer_id_pk\",\"customer_name\", \"conctact_no\",\"shipping_address\",\"country\",\"region\", \"isActive\") \n",
    "customer_dim_df.show(5) \n",
    "intsert_cnt = int(customer_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "customer_dim_df.write.save_as_table(\"sales_dwh.consumption.customer_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "def create_payment_dim(all_sales_df, session) -> None: \n",
    "payment_dim_df = all_sales_df.groupBy(col(\"COUNTRY\"),col(\"REGION\"),col(\"payment_method\"),col(\"payment_provider\")).count() \n",
    "payment_dim_df = payment_dim_df.with_column(\"isActive\",lit('Y')) \n",
    "#region_dim_df.write.save_as_table('sales_dwh.consumption.region_dim',mode=\"append\") \n",
    "payment_dim_df.show(5) \n",
    "# part 2 where delta data will be processed \n",
    "existing_payment_dim_df = session.sql(\"select payment_method,payment_provider,country, region from sales_dwh.consumption.payment_dim\") \n",
    "payment_dim_df = payment_dim_df.join(existing_payment_dim_df,[\"payment_method\",\"payment_provider\",\"country\", \"region\"],join_type='leftanti') \n",
    "payment_dim_df = payment_dim_df.selectExpr(\"sales_dwh.consumption.payment_dim_seq.nextval as payment_id_pk\",\"payment_method\", \"payment_provider\",\"country\",\"region\", \"isActive\") \n",
    "intsert_cnt = int(payment_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "payment_dim_df.write.save_as_table(\"sales_dwh.consumption.payment_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "def create_date_dim(all_sales_df, session) -> None: \n",
    "start_date = all_sales_df.select(min(\"order_dt\").alias(\"min_order_dt\")).collect()[0].as_dict()['MIN_ORDER_DT'] \n",
    "end_date = all_sales_df.select(max(\"order_dt\").alias(\"max_order_dt\")).collect()[0].as_dict()['MAX_ORDER_DT'] \n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D') \n",
    "#print(date_range) \n",
    "date_dim = pd.DataFrame() \n",
    "date_dim['order_dt'] = date_range.date \n",
    "date_dim['Year'] = date_range.year \n",
    "# Calculate day counter \n",
    "start_day_of_year = pd.to_datetime(start_date).dayofyear \n",
    "date_dim['DayCounter'] = date_range.dayofyear - start_day_of_year + 1 \n",
    "date_dim['Month'] = date_range.month \n",
    "date_dim['Quarter'] = date_range.quarter \n",
    "date_dim['Day'] = date_range.day \n",
    "date_dim['DayOfWeek'] = date_range.dayofweek \n",
    "date_dim['DayName'] = date_range.strftime('%A') \n",
    "date_dim['DayOfMonth'] = date_range.day \n",
    "date_dim['Weekday'] = date_dim['DayOfWeek'].map({0: 'Weekday', 1: 'Weekday', 2: 'Weekday', 3: 'Weekday', 4: 'Weekday', 5: 'Weekend', 6: 'Weekend'}) \n",
    "date_dim_df = session.create_dataframe(date_dim) \n",
    "existing_date_dim_df = session.sql(\"select order_dt from sales_dwh.consumption.date_dim \") \n",
    "date_dim_df = date_dim_df.join(existing_date_dim_df,existing_date_dim_df['order_dt']==date_dim_df['\"order_dt\"'],join_type='leftanti') \n",
    "date_dim_df = date_dim_df.selectExpr(' \\ \n",
    "sales_dwh.consumption.date_dim_seq.nextval, \\ \n",
    "\"order_dt\" as order_dt, \\ \n",
    "\"DayCounter\" as day_counter,\\ \n",
    "\"Year\" as order_year, \\ \n",
    "\"Month\" as order_month, \\ \n",
    "\"Quarter\" as order_quarter, \\ \n",
    "\"Day\" as order_day, \\ \n",
    "\"DayOfWeek\" as order_dayofweek, \\ \n",
    "\"DayName\" as order_dayname, \\ \n",
    "\"DayOfMonth\" as order_dayofmonth, \\ \n",
    "\"Weekday\" as order_weekday\\ \n",
    "') \n",
    "intsert_cnt = int(date_dim_df.count()) \n",
    "if intsert_cnt>0: \n",
    "date_dim_df.write.save_as_table(\"sales_dwh.consumption.date_dim\",mode=\"append\") \n",
    "print(\"save operation ran...\") \n",
    "else: \n",
    "print(\"No insert ...Opps...\") \n",
    "def main(): \n",
    "#get the session object and get dataframe \n",
    "session = get_snowpark_session() \n",
    "in_sales_df = session.sql(\"select * from sales_dwh.curated.in_sales_order\") \n",
    "us_sales_df = session.sql(\"select * from sales_dwh.curated.us_sales_order\") \n",
    "fr_sales_df = session.sql(\"select * from sales_dwh.curated.fr_sales_order\") \n",
    "all_sales_df = in_sales_df.union(us_sales_df).union(fr_sales_df) \n",
    "create_date_dim(all_sales_df,session) #date dimension \n",
    "create_region_dim(all_sales_df,session) #region dimension \n",
    "create_product_dim(all_sales_df,session) #product dimension \n",
    "create_promocode_dim(all_sales_df,session) #promot code dimension \n",
    "create_customer_dim(all_sales_df,session) #customer dimension \n",
    "create_payment_dim(all_sales_df,session) #payment dimension \n",
    "create_date_dim(all_sales_df,session) #date dimension \n",
    "date_dim_df = session.sql(\"select date_id_pk, order_dt from sales_dwh.consumption.date_dim\") \n",
    "customer_dim_df = session.sql(\"select customer_id_pk, customer_name, country, region from sales_dwh.consumption.CUSTOMER_DIM\") \n",
    "payment_dim_df = session.sql(\"select payment_id_pk, payment_method, payment_provider, country, region from sales_dwh.consumption.PAYMENT_DIM\") \n",
    "product_dim_df = session.sql(\"select product_id_pk, mobile_key from sales_dwh.consumption.PRODUCT_DIM\") \n",
    "promo_code_dim_df = session.sql(\"select promo_code_id_pk,promotion_code,country, region from sales_dwh.consumption.PROMO_CODE_DIM\") \n",
    "region_dim_df = session.sql(\"select region_id_pk,country, region from sales_dwh.consumption.REGION_DIM\") \n",
    "all_sales_df = all_sales_df.with_column( \"promotion_code\", expr(\"case when promotion_code is null then 'NA' else promotion_code end\")) \n",
    "all_sales_df = all_sales_df.join(date_dim_df, [\"order_dt\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.join(customer_dim_df, [\"customer_name\",\"region\",\"country\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.join(payment_dim_df, [\"payment_method\", \"payment_provider\", \"country\", \"region\"],join_type='inner') \n",
    "#all_sales_df = all_sales_df.join(product_dim_df, [\"brand\",\"model\",\"color\",\"Memory\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.join(product_dim_df, [\"mobile_key\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.join(promo_code_dim_df, [\"promotion_code\",\"country\", \"region\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.join(region_dim_df, [\"country\", \"region\"],join_type='inner') \n",
    "all_sales_df = all_sales_df.selectExpr(\"sales_dwh.consumption.sales_fact_seq.nextval as order_id_pk, \\ \n",
    "order_id as order_code, \\ \n",
    "date_id_pk as date_id_fk, \\ \n",
    "region_id_pk as region_id_fk, \\ \n",
    "customer_id_pk as customer_id_fk, \\ \n",
    "payment_id_pk as payment_id_fk, \\ \n",
    "product_id_pk as product_id_fk, \\ \n",
    "promo_code_id_pk as promo_code_id_fk, \\ \n",
    "order_quantity, \\ \n",
    "local_total_order_amt, \\ \n",
    "local_tax_amt, \\ \n",
    "exhchange_rate, \\ \n",
    "us_total_order_amt, \\ \n",
    "usd_tax_amt \\ \n",
    "\") \n",
    "all_sales_df.write.save_as_table(\"sales_dwh.consumption.sales_fact\",mode=\"append\") \n",
    "if __name__ == '__main__': \n",
    "main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
